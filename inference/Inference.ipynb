{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf113a12-4f16-42cb-979e-562e5597507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:24587\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [23/May/2025 16:27:33] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/May/2025 16:27:33] \"GET /static/app.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [23/May/2025 16:27:33] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [23/May/2025 16:28:34] \"POST /process HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/May/2025 16:30:06] \"GET /download/41fe2d0adaac4adb810a3594b3b94146.mp4 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/May/2025 14:58:03] \"POST /process HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/May/2025 14:58:20] \"GET /download/da0b52a162f94087ba91a4a737a550cd.mp4 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, jsonify, url_for, send_from_directory\n",
    "from pathlib import Path\n",
    "import uuid, os, cv2, numpy as np, torch, torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from aedat import Decoder   # pip install aedat\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\", template_folder=\"templates\")\n",
    "UPLOAD_FOLDER = Path(\"uploads\"); UPLOAD_FOLDER.mkdir(exist_ok=True)\n",
    "OUTPUT_FOLDER = Path(\"outputs\"); OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "# ─────────── Config ───────────────────────────────────────────────────────\n",
    "NUM_BINS, SENSOR_W, SENSOR_H = 5, 346, 260\n",
    "RESIZE_W, RESIZE_H          = 160, 120\n",
    "WIN_MS, FPS                 = 100.0, int(1000/100.0)\n",
    "BLINK_THRESH                = 0.5\n",
    "DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─────────── Model ─────────────────────────────────────────────────────────\n",
    "class SpikingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(2,32,3,padding=1);   self.bn1 = nn.BatchNorm3d(32)\n",
    "        self.conv2 = nn.Conv3d(32,64,3,padding=1);  self.bn2 = nn.BatchNorm3d(64)\n",
    "        self.conv3 = nn.Conv3d(64,128,3,padding=1); self.bn3 = nn.BatchNorm3d(128)\n",
    "        self.pool  = nn.AdaptiveAvgPool3d(1)\n",
    "        self.act   = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid())\n",
    "        self.fc1   = nn.Linear(128 + RESIZE_W*RESIZE_H, 64)\n",
    "        self.drop  = nn.Dropout(0.4)\n",
    "        self.blink_head  = nn.Linear(64, 1)\n",
    "        self.centre_head = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, cnt):\n",
    "        out,_ = self.act(self.bn1(self.conv1(x)))\n",
    "        out,_ = self.act(self.bn2(self.conv2(out)))\n",
    "        out,_ = self.act(self.bn3(self.conv3(out)))\n",
    "        feat     = self.pool(out).view(out.size(0), -1)\n",
    "        cnt_flat = cnt.view(out.size(0), -1)\n",
    "        h        = torch.relu(self.fc1(torch.cat([feat, cnt_flat], dim=1)))\n",
    "        h        = self.drop(h)\n",
    "        return self.blink_head(h), self.centre_head(h)\n",
    "\n",
    "# ─────────── Read AEDAT4 via aedat.Decoder ───────────────────────────────\n",
    "def read_aedat4(path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parse .aedat4 into an (N,4) array [x, y, t_us, polarity].\n",
    "    Supports:\n",
    "      • object‐style packets: packet.x, packet.y, packet.timestamp, packet.polarity\n",
    "      • dict‐style packets with a nested 'events' structured array\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    dec = Decoder(str(path))\n",
    "\n",
    "    for i, packet in enumerate(dec):\n",
    "        # object‐style\n",
    "        if not isinstance(packet, dict):\n",
    "            xs = packet.x\n",
    "            ys = packet.y\n",
    "            ts = packet.timestamp\n",
    "            ps = packet.polarity\n",
    "\n",
    "        # dict‐style, expect packet['events'] to be a structured numpy array\n",
    "        else:\n",
    "            ev_arr = packet.get(\"events\")\n",
    "            if ev_arr is None:\n",
    "                raise KeyError(f\"Packet #{i} dict keys = {packet.keys()} (no 'events')\")\n",
    "            names = ev_arr.dtype.names or []\n",
    "            # grab the correct field names\n",
    "            try:\n",
    "                xs = ev_arr[\"x\"]\n",
    "                ys = ev_arr[\"y\"]\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"Packet #{i} events fields = {names} (need 'x','y')\")\n",
    "            # timestamp: could be 't', 'ts', or 'timestamp'\n",
    "            if \"t\" in names:\n",
    "                ts = ev_arr[\"t\"]\n",
    "            elif \"timestamp\" in names:\n",
    "                ts = ev_arr[\"timestamp\"]\n",
    "            else:\n",
    "                raise KeyError(f\"Packet #{i} events fields = {names} (need 't' or 'timestamp')\")\n",
    "            # polarity: could be 'p' or 'polarity'\n",
    "            if \"p\" in names:\n",
    "                ps = ev_arr[\"p\"]\n",
    "            elif \"polarity\" in names:\n",
    "                ps = ev_arr[\"polarity\"]\n",
    "            else:\n",
    "                raise KeyError(f\"Packet #{i} events fields = {names} (need 'p' or 'polarity')\")\n",
    "\n",
    "        ev = np.column_stack([\n",
    "            xs.astype(np.int32),\n",
    "            ys.astype(np.int32),\n",
    "            ts.astype(np.int64),\n",
    "            ps.astype(np.int8),\n",
    "        ])\n",
    "        events.append(ev)\n",
    "\n",
    "    if not events:\n",
    "        return np.zeros((0, 4), dtype=np.int64)\n",
    "    return np.vstack(events)\n",
    "\n",
    "\n",
    "\n",
    "# ─────────── Voxel encoding ────────────────────────────────────────────────\n",
    "def events_to_voxel(events, t0, t1):\n",
    "    T   = NUM_BINS\n",
    "    vox = np.zeros((T, 2, SENSOR_H, SENSOR_W), np.float32)\n",
    "    dt  = (t1 - t0) / T\n",
    "    mask = (events[:,2] >= t0) & (events[:,2] < t1)\n",
    "    sl   = events[mask]\n",
    "    if sl.size:\n",
    "        bins = ((sl[:,2] - t0) / dt).astype(int)\n",
    "        np.clip(bins, 0, T-1, out=bins)\n",
    "        for b, (x, y, p) in zip(bins, sl[:, [0,1,3]].astype(int)):\n",
    "            if 0 <= x < SENSOR_W and 0 <= y < SENSOR_H:\n",
    "                vox[b, p, y, x] += 1\n",
    "    vox = np.clip(vox, -3, 3)\n",
    "\n",
    "    # Downsample spatially\n",
    "    small = np.zeros((T, 2, RESIZE_H, RESIZE_W), np.float32)\n",
    "    for t in range(T):\n",
    "        for c in range(2):\n",
    "            small[t, c] = cv2.resize(\n",
    "                vox[t, c],\n",
    "                (RESIZE_W, RESIZE_H),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    return small\n",
    "\n",
    "# ─────────── Load model once ────────────────────────────────────────────────\n",
    "MODEL_PATH = Path(\"model/blink_centre_model.pth\")\n",
    "model      = SpikingCNN().to(DEVICE)\n",
    "state      = torch.load(str(MODEL_PATH), map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ─────────── Flask routes ─────────────────────────────────────────────────\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/process\", methods=[\"POST\"])\n",
    "def process_file():\n",
    "    try:\n",
    "        # 1) Save upload\n",
    "        f = request.files[\"aedat\"]\n",
    "        uid = uuid.uuid4().hex\n",
    "        in_path  = UPLOAD_FOLDER / f\"{uid}.aedat4\"\n",
    "        out_path = OUTPUT_FOLDER / f\"{uid}.mp4\"\n",
    "        f.save(str(in_path))\n",
    "\n",
    "        # 2) Read all events\n",
    "        events = read_aedat4(in_path)\n",
    "        if events.shape[0] == 0:\n",
    "            return jsonify(error=\"No events found in AEDAT file\"), 400\n",
    "\n",
    "        # 3) Prepare video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        writer = cv2.VideoWriter(str(out_path), fourcc, FPS, (RESIZE_W,RESIZE_H))\n",
    "\n",
    "        # 4) Slide windows & inference\n",
    "        win_us = int(WIN_MS * 1000)\n",
    "        t0     = int(events[0,2])\n",
    "        t_end  = int(events[-1,2])\n",
    "        n_win  = (t_end - t0) // win_us\n",
    "\n",
    "        for _ in range(int(n_win)):\n",
    "            t1  = t0 + win_us\n",
    "            vox = events_to_voxel(events, t0, t1)\n",
    "            t0 += win_us\n",
    "\n",
    "            x   = torch.from_numpy(vox) \\\n",
    "                        .permute(1,0,2,3).unsqueeze(0) \\\n",
    "                        .to(DEVICE)\n",
    "            cnt = x.abs().sum(dim=(1,2), keepdim=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                blink_logit, centre = model(x, cnt)\n",
    "                prob = torch.sigmoid(blink_logit).item()\n",
    "\n",
    "            label = \"blink\" if prob > BLINK_THRESH else \"open\"\n",
    "            cx = int(centre[0,0].clamp(0,1).item() * RESIZE_W)\n",
    "            cy = int(centre[0,1].clamp(0,1).item() * RESIZE_H)\n",
    "\n",
    "            cm     = cnt.squeeze().cpu().numpy()\n",
    "            cm_img = (cm / (cm.max()+1e-6) * 255).astype(np.uint8)\n",
    "            frame  = cv2.cvtColor(cm_img, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0,0,255), -1)\n",
    "            cv2.putText(frame, label, (5,20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                        (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "        writer.release()\n",
    "\n",
    "        download_url = url_for(\"download_file\", filename=out_path.name)\n",
    "        return jsonify(video_url=download_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the traceback on the server\n",
    "        import traceback; traceback.print_exc()\n",
    "        return jsonify(error=str(e)), 500\n",
    "\n",
    "\n",
    "@app.route(\"/download/<filename>\")\n",
    "def download_file(filename):\n",
    "    return send_from_directory(OUTPUT_FOLDER, filename, as_attachment=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, port=24587)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ebc2d-d97e-4940-baa2-7f2eff685a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
